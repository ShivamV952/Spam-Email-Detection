{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eVQzVnyRwW9g",
    "outputId": "bc00f68b-181c-4541-8c8b-386b975b5c92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in ./myenv/lib/python3.10/site-packages (1.9.3)\n",
      "Requirement already satisfied: pillow in ./myenv/lib/python3.10/site-packages (from wordcloud) (11.0.0)\n",
      "Requirement already satisfied: matplotlib in ./myenv/lib/python3.10/site-packages (from wordcloud) (3.9.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in ./myenv/lib/python3.10/site-packages (from wordcloud) (2.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./myenv/lib/python3.10/site-packages (from matplotlib->wordcloud) (3.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.10/site-packages (from matplotlib->wordcloud) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./myenv/lib/python3.10/site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./myenv/lib/python3.10/site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./myenv/lib/python3.10/site-packages (from matplotlib->wordcloud) (1.4.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./myenv/lib/python3.10/site-packages (from matplotlib->wordcloud) (1.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./myenv/lib/python3.10/site-packages (from matplotlib->wordcloud) (4.54.1)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Kaggle Dataset : https://www.kaggle.com/code/mohitr/simple-spam-filter/data\n",
    "\n",
    "%pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfYiMXA6wosv"
   },
   "outputs": [],
   "source": [
    "# Required Packages\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sx1OFfIBxBIZ",
    "outputId": "e90f005a-5448-4ede-87f0-29f8f40c2ecf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dhananjay/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dhananjay/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/dhananjay/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/dhananjay/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "g6IpQPXSxJFm"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('content/emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TYK0vWOMxPiY",
    "outputId": "2cb74b5e-5acd-4f59-ff74-cfc68932a9a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileSystemPathPointer('/home/dhananjay/nltk_data/tokenizers/punkt')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.data.find('tokenizers/punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KxtCGOauxWWf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/dhananjay/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Subject: naturally irresistible your corporate...   \n",
      "1  Subject: the stock trading gunslinger  fanny i...   \n",
      "2  Subject: unbelievable new homes made easy  im ...   \n",
      "3  Subject: 4 color printing special  request add...   \n",
      "4  Subject: do not have money , get software cds ...   \n",
      "\n",
      "                                              tokens  \n",
      "0  [Subject, :, naturally, irresistible, your, co...  \n",
      "1  [Subject, :, the, stock, trading, gunslinger, ...  \n",
      "2  [Subject, :, unbelievable, new, homes, made, e...  \n",
      "3  [Subject, :, 4, color, printing, special, requ...  \n",
      "4  [Subject, :, do, not, have, money, ,, get, sof...  \n"
     ]
    }
   ],
   "source": [
    "# First, we convert each text to an array of tokens\n",
    "nltk.download('punkt_tab')\n",
    "if 'text' in df.columns:\n",
    "    # Tokenizing the text column\n",
    "    df['tokens'] = df['text'].map(lambda text: nltk.tokenize.word_tokenize(text), na_action=None)\n",
    "    # Display the DataFrame with tokens\n",
    "    print(df[['text', 'tokens']].head())\n",
    "else:\n",
    "    print(\"Column 'text' does not exist in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "AHYqZ4vnxhcR"
   },
   "outputs": [],
   "source": [
    "# Then, with the help of the nltk package, we remove the stop words.\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "df['filtered_text'] = df['tokens'].map(lambda tokens: [w for w in tokens if not w in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "xs70Prs_yGCl"
   },
   "outputs": [],
   "source": [
    "# Since every email in our dataset starts with the part \"Subject :\", we remove it\n",
    "# to reduce complexity.\n",
    "\n",
    "df['filtered_text'] = df['filtered_text'].map(lambda text: text[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1ojMDqKjyh6f"
   },
   "outputs": [],
   "source": [
    "# Since the special characters in the texts have no value for us, we remove them.\n",
    "\n",
    "df['filtered_text'] = df['filtered_text'].map(lambda text: ' '.join(text))\n",
    "\n",
    "#removing apecial characters from each mail \n",
    "df['filtered_text'] = df['filtered_text'].map(lambda text: re.sub('[^A-Za-z0-9]+', ' ', text))\n",
    "\n",
    "#removing numbers\n",
    "df['filtered_text'] = df['filtered_text'].map(lambda text: re.sub('[0-9]+', ' ', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "GLEAx1XnyyuH"
   },
   "outputs": [],
   "source": [
    "# Lemmatization, we converts words into their simple form. \"running\", \"ran\" => \"run\"\n",
    "\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "df['filtered_text'] = df['filtered_text'].map(lambda text: wnl.lemmatize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "PHpauGOCzg5Q"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"content/filtered.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
